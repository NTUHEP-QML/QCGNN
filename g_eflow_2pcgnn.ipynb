{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 3020616\n"
     ]
    }
   ],
   "source": [
    "# basic packages\n",
    "import os, time, sys\n",
    "import argparse\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model template\n",
    "import m_nn\n",
    "import m_lightning\n",
    "\n",
    "# data\n",
    "import d_mg5_data\n",
    "import awkward as ak\n",
    "\n",
    "# qml\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "\n",
    "# pytorch_lightning\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "\n",
    "# pytorch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "# wandb\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "wandb.login()\n",
    "\n",
    "# reproducibility\n",
    "L.seed_everything(3020616)\n",
    "\n",
    "# faster calculation on GPU but less precision\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "# directory for saving results\n",
    "root_dir = f\"./result\"\n",
    "if os.path.isdir(root_dir) == False:\n",
    "    os.makedirs(root_dir)\n",
    "\n",
    "# argparser\n",
    "use_parser = False\n",
    "if use_parser:\n",
    "    parser = argparse.ArgumentParser(description='Determine the structure of the quantum model.')\n",
    "    parser.add_argument('--date_time', type=str, help='Date time in format Ymd_HMS')\n",
    "    parser.add_argument('--q_gnn_layers', type=int, help='Quantum gnn layers')\n",
    "    parser.add_argument('--q_gnn_reupload', type=int, help='Quantum gnn reupload')\n",
    "    parser.add_argument('--rnd_seed', type=int, help='Random seed')\n",
    "    parse_args = parser.parse_args()\n",
    "else:\n",
    "    parse_fields = [\"date_time\", \"q_gnn_layers\", \"q_gnn_reupload\", \"q_gnn_num_qnn\", \"rnd_seed\"]\n",
    "    parse_tuple  = namedtuple('parse_tuple', \" \".join(parse_fields))\n",
    "    parse_args   = parse_tuple(\n",
    "        date_time      = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime()),\n",
    "        rnd_seed       = 0,\n",
    "        q_gnn_layers   = 2,\n",
    "        q_gnn_reupload = 0,\n",
    "        q_gnn_num_qnn  = 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "cf = {}\n",
    "cf[\"time\"]     = input(\"Type a date time or leave it space to use default date time: \") or parse_args.date_time\n",
    "cf[\"wandb\"]    = True # <-----------------------------------------------\n",
    "cf[\"project\"]  = \"g_eflow_QFCGNN\"\n",
    "\n",
    "# training configuration\n",
    "cf[\"lr\"]                = 1E-3\n",
    "cf[\"rnd_seed\"]          = parse_args.rnd_seed\n",
    "cf[\"num_train_ratio\"]   = 0.8\n",
    "cf[\"num_bin_data\"]      = 500 # <-----------------------------------------------\n",
    "cf[\"batch_size\"]        = 64 # <-----------------------------------------------\n",
    "cf[\"num_workers\"]       = 0\n",
    "cf[\"max_epochs\"]        = 20 # <-----------------------------------------------\n",
    "cf[\"accelerator\"]       = \"cpu\"\n",
    "cf[\"fast_dev_run\"]      = False\n",
    "cf[\"log_every_n_steps\"] = cf[\"batch_size\"] // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "class JetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, sig_events, bkg_events, mode=None, graph=True):\n",
    "        super().__init__()\n",
    "        # whether transform to torch_geometric graph data\n",
    "        self.graph = graph\n",
    "\n",
    "        # jet events\n",
    "        self.max_num_ptcs = max(\n",
    "            max(ak.count(sig_events[\"fast_pt\"], axis=1)),\n",
    "            max(ak.count(bkg_events[\"fast_pt\"], axis=1)))\n",
    "        sig_events = self._preprocess(sig_events, mode)\n",
    "        bkg_events = self._preprocess(bkg_events, mode)\n",
    "        print(f\"\\nDataLog: Max number of particles = {self.max_num_ptcs}\\n\")\n",
    "\n",
    "        # prepare dataset for dataloader\n",
    "        train_idx = int(cf[\"num_train_ratio\"] * len(sig_events))\n",
    "        self.train_dataset = self._dataset(sig_events[:train_idx], 1) + self._dataset(bkg_events[:train_idx], 0)\n",
    "        self.test_dataset  = self._dataset(sig_events[train_idx:], 1) + self._dataset(bkg_events[train_idx:], 0)\n",
    "\n",
    "    def _preprocess(self, events, mode):\n",
    "        # \"_\" prefix means that it is a fastjet feature\n",
    "        if mode == \"normalize\":\n",
    "            f1 = np.arctan(events[\"fast_pt\"] / events[\"fatjet_pt\"])\n",
    "            f2 = events[\"fast_delta_eta\"]\n",
    "            f3 = events[\"fast_delta_phi\"]\n",
    "            arrays = ak.zip([f1, f2, f3])\n",
    "        elif mode == \"normalize_pi\":\n",
    "            fatjet_radius = 0.8\n",
    "            f1 = np.arctan(events[\"fast_pt\"] / events[\"fatjet_pt\"])\n",
    "            f2 = events[\"fast_delta_eta\"] / fatjet_radius * (np.pi/2)\n",
    "            f3 = events[\"fast_delta_phi\"] / fatjet_radius * (np.pi/2)\n",
    "            arrays = ak.zip([f1, f2, f3])\n",
    "        elif mode == \"tri_eflow\":\n",
    "            f1_s = np.sin(np.arctan(events[\"fast_pt\"] / events[\"fatjet_pt\"])/2)\n",
    "            f1_c = np.cos(np.arctan(events[\"fast_pt\"] / events[\"fatjet_pt\"])/2)\n",
    "            f2_s = np.sin(events[\"fast_delta_eta\"]/2)\n",
    "            f2_c = np.cos(events[\"fast_delta_eta\"]/2)\n",
    "            f3_s = np.sin(events[\"fast_delta_phi\"]/2)\n",
    "            f3_c = np.cos(events[\"fast_delta_phi\"]/2)\n",
    "            arrays = ak.zip([f1_s, f1_c, f2_s, f2_c, f3_s, f3_c])\n",
    "        elif mode == \"tri_eflow_pi\":\n",
    "            fatjet_radius = 0.8\n",
    "            f1_s = np.sin(np.arctan(events[\"fast_pt\"] / events[\"fatjet_pt\"]) / 2)\n",
    "            f1_c = np.cos(np.arctan(events[\"fast_pt\"] / events[\"fatjet_pt\"]) / 2)\n",
    "            f2_s = np.sin((events[\"fast_delta_eta\"] / fatjet_radius * (np.pi/2)) / 2)\n",
    "            f2_c = np.cos((events[\"fast_delta_eta\"] / fatjet_radius * (np.pi/2)) / 2)\n",
    "            f3_s = np.sin((events[\"fast_delta_phi\"] / fatjet_radius * (np.pi/2)) / 2)\n",
    "            f3_c = np.cos((events[\"fast_delta_phi\"] / fatjet_radius * (np.pi/2)) / 2)\n",
    "            arrays = ak.zip([f1_s, f1_c, f2_s, f2_c, f3_s, f3_c])\n",
    "        elif mode == \"\":\n",
    "            f1 = events[\"fast_pt\"]\n",
    "            f2 = events[\"fast_delta_eta\"]\n",
    "            f3 = events[\"fast_delta_phi\"]\n",
    "            arrays = ak.zip([f1, f2, f3])\n",
    "        arrays = arrays.to_list()\n",
    "        events = [torch.tensor(arrays[i], dtype=torch.float32, requires_grad=False) for i in range(len(arrays))]\n",
    "        return events\n",
    "\n",
    "    def _dataset(self, events, y):\n",
    "        if self.graph == True:\n",
    "            # create pytorch_geometric \"Data\" object\n",
    "            dataset = []\n",
    "            for i in range(len(events)):\n",
    "                x = events[i]\n",
    "                edge_index = list(product(range(len(x)), range(len(x))))\n",
    "                edge_index = torch.tensor(edge_index, requires_grad=False).transpose(0, 1)\n",
    "                dataset.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "        else:\n",
    "            pad     = lambda x: torch.nn.functional.pad(x, (0,0,0,self.max_num_ptcs-len(x)), mode=\"constant\", value=0)\n",
    "            dataset = TorchDataset(x=[pad(events[i]) for i in range(len(events))], y=[y]*len(events))\n",
    "        return dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.graph == True:\n",
    "            return GeoDataLoader(self.train_dataset, batch_size=cf[\"batch_size\"], shuffle=True)\n",
    "        else:\n",
    "            return TorchDataLoader(self.train_dataset, batch_size=cf[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if self.graph == True:\n",
    "            return GeoDataLoader(self.test_dataset, batch_size=cf[\"batch_size\"], shuffle=False)\n",
    "        else:\n",
    "            return TorchDataLoader(self.test_dataset, batch_size=cf[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.graph == True:\n",
    "            return GeoDataLoader(self.test_dataset, batch_size=cf[\"batch_size\"], shuffle=False)\n",
    "        else:\n",
    "            return TorchDataLoader(self.test_dataset, batch_size=cf[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassing(MessagePassing):\n",
    "    def __init__(self, phi):\n",
    "        super().__init__(aggr=\"add\", flow=\"target_to_source\")\n",
    "        self.phi = phi\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)\n",
    "    def message(self, x_i, x_j):\n",
    "        return self.phi(torch.cat((x_i, x_j), dim=-1))\n",
    "    def update(self, aggr_out, x):\n",
    "        return aggr_out\n",
    "\n",
    "class Graph2PCGNN(nn.Module):\n",
    "    def __init__(self, phi, mlp):\n",
    "        super().__init__()\n",
    "        self.gnn = MessagePassing(phi)\n",
    "        self.mlp = mlp\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.gnn(x, edge_index)\n",
    "        x = geom_nn.global_add_pool(x, batch)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "class Classical2PCGNN(Graph2PCGNN):\n",
    "    def __init__(self, gnn_in, gnn_out, gnn_hidden, gnn_layers, mlp_hidden=0, mlp_layers=0, **kwargs):\n",
    "        phi = m_nn.ClassicalMLP(in_channel=gnn_in, out_channel=gnn_out, hidden_channel=gnn_hidden, num_layers=gnn_layers)\n",
    "        mlp = m_nn.ClassicalMLP(in_channel=gnn_out, out_channel=1, hidden_channel=mlp_hidden, num_layers=mlp_layers)\n",
    "        super().__init__(phi, mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Trivial GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumAngle2PCGNN(Graph2PCGNN):\n",
    "    def __init__(self, gnn_qubits, gnn_layers, gnn_reupload, gnn_measurements, **kwargs):\n",
    "        phi = m_nn.QuantumMLP(num_qubits=gnn_qubits, num_layers=gnn_layers, num_reupload=gnn_reupload, measurements=gnn_measurements)\n",
    "        mlp = m_nn.ClassicalMLP(in_channel=len(gnn_measurements), out_channel=1, hidden_channel=0, num_layers=0)\n",
    "        super().__init__(phi, mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Fully Connected GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumFCGNN(nn.Module):\n",
    "    def __init__(self, gnn_idx_qubits, gnn_nn_qubits, gnn_layers, gnn_reupload, gnn_num_qnn, ctrl_enc_operator, **kwargs):\n",
    "        super().__init__()\n",
    "        self.phi = nn.ModuleList([\n",
    "            m_nn.QuantumDisorderedFCGraph(\n",
    "                num_idx_qubits    = gnn_idx_qubits, \n",
    "                num_nn_qubits     = gnn_nn_qubits, \n",
    "                num_layers        = gnn_layers, \n",
    "                num_reupload      = gnn_reupload,\n",
    "                ctrl_enc_operator = ctrl_enc_operator,\n",
    "                ) for _ in range(gnn_num_qnn)\n",
    "                ])\n",
    "        self.mlp = m_nn.ClassicalMLP(in_channel=gnn_num_qnn*gnn_nn_qubits, out_channel=1, hidden_channel=0, num_layers=0)\n",
    "    def forward(self, x):\n",
    "        # inputs should be 1-dim for each data, otherwise it would be confused with batch shape\n",
    "        x = torch.flatten(x, start_dim=-2, end_dim=-1)\n",
    "        x = torch.cat([self.phi[i](x) for i in range(len(self.phi))], dim=-1)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "class QuantumRyFCGNN(QuantumFCGNN):\n",
    "    def __init__(self, gnn_idx_qubits, gnn_nn_qubits, gnn_layers, gnn_reupload, gnn_num_qnn, **kwargs):\n",
    "        def ctrl_enc_operator(_input, control, control_values):\n",
    "            ctrl = qml.ctrl(qml.AngleEmbedding, control=control, control_values=control_values)\n",
    "            ctrl(features=_input, wires=range(gnn_idx_qubits, gnn_idx_qubits+3), rotation=\"Y\")\n",
    "        super().__init__(gnn_idx_qubits, gnn_nn_qubits, gnn_layers, gnn_reupload, gnn_num_qnn, ctrl_enc_operator, **kwargs)\n",
    "    \n",
    "class QuantumRotFCGNN(QuantumFCGNN):\n",
    "    def __init__(self, gnn_idx_qubits, gnn_nn_qubits, gnn_layers, gnn_reupload, gnn_num_qnn, **kwargs):\n",
    "        def ctrl_enc_operator(_input, control, control_values):\n",
    "            qml.Hadamard(wires=gnn_idx_qubits)\n",
    "            ctrl = qml.ctrl(qml.Rot, control=control, control_values=control_values)\n",
    "            ctrl(theta=_input[0], phi=_input[1], omega=_input[2], wires=gnn_idx_qubits)\n",
    "        super().__init__(gnn_idx_qubits, gnn_nn_qubits, gnn_layers, gnn_reupload, gnn_num_qnn, ctrl_enc_operator, **kwargs)\n",
    "\n",
    "# class QuantumAmpFCGNN(QuantumFCGNN):\n",
    "#     def __init__(self, gnn_idx_qubits, gnn_nn_qubits, gnn_layers, gnn_reupload, gnn_num_qnn, **kwargs):\n",
    "#         def ctrl_enc_operator(_input, control, control_values):\n",
    "#             ctrl = qml.ctrl(qml.AmplitudeEmbedding, control=control, control_values=control_values)\n",
    "#             ctrl(features=_input, wires=range(gnn_idx_qubits, gnn_idx_qubits+2), pad_with=np.pi/2, normalize=True)\n",
    "#         super().__init__(gnn_idx_qubits, gnn_nn_qubits, gnn_layers, gnn_reupload, gnn_num_qnn, ctrl_enc_operator, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_module, train_info, graph=True):\n",
    "    # setup wandb logger\n",
    "    wandb_info = {}\n",
    "    if cf[\"wandb\"]:\n",
    "        wandb_info[\"project\"]  = cf[\"project\"]\n",
    "        wandb_info[\"group\"]    = f\"{train_info['sig']}_{train_info['bkg']}\"\n",
    "        wandb_info[\"name\"]     = f\"{train_info['group_rnd']} | {cf['time']}_{train_info['rnd_seed']}\"\n",
    "        wandb_info[\"id\"]       = wandb_info[\"name\"]\n",
    "        wandb_info[\"save_dir\"] = root_dir \n",
    "        wandb_logger = WandbLogger(**wandb_info)\n",
    "        wandb_config = {}\n",
    "        wandb_config.update(cf)\n",
    "        wandb_config.update(train_info)\n",
    "        wandb_config.update(wandb_info)\n",
    "        wandb_logger.experiment.config.update(wandb_config)\n",
    "        wandb_logger.watch(model, log=\"all\")\n",
    "\n",
    "    # start lightning training\n",
    "    logger  = wandb_logger if cf[\"wandb\"] else None\n",
    "    trainer = L.Trainer(\n",
    "        logger               = logger, \n",
    "        accelerator          = cf[\"accelerator\"],\n",
    "        max_epochs           = cf[\"max_epochs\"],\n",
    "        fast_dev_run         = cf[\"fast_dev_run\"],\n",
    "        log_every_n_steps    = cf[\"log_every_n_steps\"],\n",
    "        num_sanity_val_steps = 0,\n",
    "        )\n",
    "    litmodel = m_lightning.BinaryLitModel(model, lr=cf[\"lr\"], graph=graph)\n",
    "\n",
    "    # load ckpt file if exists\n",
    "    try:\n",
    "        ckpt_dir = f\"result/{cf['project']}/{wandb_info['id']}/checkpoints\"\n",
    "        for _file in os.listdir(ckpt_dir):\n",
    "            if _file.endswith(\"ckpt\"):\n",
    "                ckpt_path = f\"{ckpt_dir}/{_file}\"\n",
    "    except:\n",
    "        ckpt_path = None\n",
    "\n",
    "    # print information\n",
    "    print(\"-------------------- Training information --------------------\\n\")\n",
    "    print(\"model:\", model.__class__.__name__, model, \"\")\n",
    "    print(\"config:\", cf, \"\")\n",
    "    print(\"train_info:\", train_info, \"\")\n",
    "    print(\"wandb_info:\", wandb_info, \"\")\n",
    "    print(\"--------------------------------------------------------------\\n\")\n",
    "    \n",
    "    trainer.fit(litmodel, datamodule=data_module, ckpt_path=ckpt_path)\n",
    "    trainer.test(litmodel, datamodule=data_module)\n",
    "\n",
    "    # finish wandb monitoring\n",
    "    if cf[\"wandb\"]:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLog: Now loading hdf5 file VzToZhToVevebb|c800_1000_r0.2.hdf5\n",
      "DataLog: Successfully loading hdf5 file VzToZhToVevebb|c800_1000_r0.2.hdf5\n",
      "DataLog: Now loading hdf5 file VzToQCD|c800_1000_r0.2.hdf5\n",
      "DataLog: Successfully loading hdf5 file VzToQCD|c800_1000_r0.2.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLog: Generate uniform Pt events (1/10) | number of bin events = 1/11075\n",
      "DataLog: Generate uniform Pt events (2/10) | number of bin events = 1/11328\n",
      "DataLog: Generate uniform Pt events (3/10) | number of bin events = 1/11761\n",
      "DataLog: Generate uniform Pt events (4/10) | number of bin events = 1/11922\n",
      "DataLog: Generate uniform Pt events (5/10) | number of bin events = 1/11775\n",
      "DataLog: Generate uniform Pt events (6/10) | number of bin events = 1/11568\n",
      "DataLog: Generate uniform Pt events (7/10) | number of bin events = 1/11036\n",
      "DataLog: Generate uniform Pt events (8/10) | number of bin events = 1/10258\n",
      "DataLog: Generate uniform Pt events (9/10) | number of bin events = 1/8917\n",
      "DataLog: Generate uniform Pt events (10/10) | number of bin events = 1/7399\n",
      "DataLog: Generate uniform Pt events (1/10) | number of bin events = 1/7571\n",
      "DataLog: Generate uniform Pt events (2/10) | number of bin events = 1/7740\n",
      "DataLog: Generate uniform Pt events (3/10) | number of bin events = 1/7967\n",
      "DataLog: Generate uniform Pt events (4/10) | number of bin events = 1/8202\n",
      "DataLog: Generate uniform Pt events (5/10) | number of bin events = 1/8472\n",
      "DataLog: Generate uniform Pt events (6/10) | number of bin events = 1/8506\n",
      "DataLog: Generate uniform Pt events (7/10) | number of bin events = 1/8624\n",
      "DataLog: Generate uniform Pt events (8/10) | number of bin events = 1/8367\n",
      "DataLog: Generate uniform Pt events (9/10) | number of bin events = 1/7864\n",
      "DataLog: Generate uniform Pt events (10/10) | number of bin events = 1/7010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | QuantumAngle2PCGNN | 25    \n",
      "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
      "-------------------------------------------------\n",
      "25        Trainable params\n",
      "0         Non-trainable params\n",
      "25        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataLog: Max number of particles = 4\n",
      "\n",
      "-------------------- Training information --------------------\n",
      "\n",
      "model: QuantumAngle2PCGNN QuantumAngle2PCGNN(\n",
      "  (gnn): MessagePassing()\n",
      "  (mlp): ClassicalMLP(\n",
      "    (net): Linear(in_features=6, out_features=1, bias=True)\n",
      "  )\n",
      ") \n",
      "config: {'time': '20230916_195512', 'wandb': False, 'project': 'g_eflow_QFCGNN', 'lr': 0.001, 'rnd_seed': 0, 'num_train_ratio': 0.8, 'num_bin_data': 1, 'batch_size': 64, 'num_workers': 0, 'max_epochs': 1, 'accelerator': 'cpu', 'fast_dev_run': False, 'log_every_n_steps': 32} \n",
      "train_info: {'rnd_seed': 0, 'model_name': 'QuantumAngle2PCGNN', 'preprocess_mode': 'normalize_pi', 'group_rnd': 'QuantumAngle2PCGNN_normalize_pi_gr0_gl1 | cut(800, 1000)_ptc4_bin10-1_R0.2', 'gnn_layers': 1, 'gnn_reupload': 0, 'gnn_qubits': 6, 'gnn_measurements': [(0, 'Z'), (1, 'Z'), (2, 'Z'), (3, 'Z'), (4, 'Z'), (5, 'Z')], 'sig': 'VzToZhToVevebb', 'bkg': 'VzToQCD', 'cut': (800, 1000), 'bin': 10, 'subjet_radius': 0.2, 'num_bin_data': 1, 'num_ptcs_limit': None, 'num_pt_ptcs': 4} \n",
      "wandb_info: {} \n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=32). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76abe83425a43a6b33cc96671adf3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52c2a4116f5434989ed0eeef00e2341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d49c4831e14497805e2712eff3b7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_roc_auc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.75            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_roc_auc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.75           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | QuantumAngle2PCGNN | 43    \n",
      "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
      "-------------------------------------------------\n",
      "43        Trainable params\n",
      "0         Non-trainable params\n",
      "43        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataLog: Max number of particles = 4\n",
      "\n",
      "-------------------- Training information --------------------\n",
      "\n",
      "model: QuantumAngle2PCGNN QuantumAngle2PCGNN(\n",
      "  (gnn): MessagePassing()\n",
      "  (mlp): ClassicalMLP(\n",
      "    (net): Linear(in_features=6, out_features=1, bias=True)\n",
      "  )\n",
      ") \n",
      "config: {'time': '20230916_195512', 'wandb': False, 'project': 'g_eflow_QFCGNN', 'lr': 0.001, 'rnd_seed': 0, 'num_train_ratio': 0.8, 'num_bin_data': 1, 'batch_size': 64, 'num_workers': 0, 'max_epochs': 1, 'accelerator': 'cpu', 'fast_dev_run': False, 'log_every_n_steps': 32} \n",
      "train_info: {'rnd_seed': 0, 'model_name': 'QuantumAngle2PCGNN', 'preprocess_mode': 'normalize_pi', 'group_rnd': 'QuantumAngle2PCGNN_normalize_pi_gr1_gl1 | cut(800, 1000)_ptc4_bin10-1_R0.2', 'gnn_layers': 1, 'gnn_reupload': 1, 'gnn_qubits': 6, 'gnn_measurements': [(0, 'Z'), (1, 'Z'), (2, 'Z'), (3, 'Z'), (4, 'Z'), (5, 'Z')], 'sig': 'VzToZhToVevebb', 'bkg': 'VzToQCD', 'cut': (800, 1000), 'bin': 10, 'subjet_radius': 0.2, 'num_bin_data': 1, 'num_ptcs_limit': None, 'num_pt_ptcs': 4} \n",
      "wandb_info: {} \n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=32). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f774a0ebf06a491a9ec1dbac284b248b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05531a33a2c475a9be2fcb0c66351df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62284f4891c947acba33cbe5c562f6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_roc_auc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.25            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_roc_auc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.25           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | QuantumAngle2PCGNN | 43    \n",
      "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
      "-------------------------------------------------\n",
      "43        Trainable params\n",
      "0         Non-trainable params\n",
      "43        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataLog: Max number of particles = 4\n",
      "\n",
      "-------------------- Training information --------------------\n",
      "\n",
      "model: QuantumAngle2PCGNN QuantumAngle2PCGNN(\n",
      "  (gnn): MessagePassing()\n",
      "  (mlp): ClassicalMLP(\n",
      "    (net): Linear(in_features=6, out_features=1, bias=True)\n",
      "  )\n",
      ") \n",
      "config: {'time': '20230916_195512', 'wandb': False, 'project': 'g_eflow_QFCGNN', 'lr': 0.001, 'rnd_seed': 0, 'num_train_ratio': 0.8, 'num_bin_data': 1, 'batch_size': 64, 'num_workers': 0, 'max_epochs': 1, 'accelerator': 'cpu', 'fast_dev_run': False, 'log_every_n_steps': 32} \n",
      "train_info: {'rnd_seed': 0, 'model_name': 'QuantumAngle2PCGNN', 'preprocess_mode': 'normalize_pi', 'group_rnd': 'QuantumAngle2PCGNN_normalize_pi_gr0_gl2 | cut(800, 1000)_ptc4_bin10-1_R0.2', 'gnn_layers': 2, 'gnn_reupload': 0, 'gnn_qubits': 6, 'gnn_measurements': [(0, 'Z'), (1, 'Z'), (2, 'Z'), (3, 'Z'), (4, 'Z'), (5, 'Z')], 'sig': 'VzToZhToVevebb', 'bkg': 'VzToQCD', 'cut': (800, 1000), 'bin': 10, 'subjet_radius': 0.2, 'num_bin_data': 1, 'num_ptcs_limit': None, 'num_pt_ptcs': 4} \n",
      "wandb_info: {} \n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=32). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb5c7f89af049b7a2d4caee308601aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05128f2ec664d7899dbe8b0d11d01d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102b6e4f1d5c471591c19b6cfdf6f295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_roc_auc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_roc_auc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | QuantumAngle2PCGNN | 79    \n",
      "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
      "-------------------------------------------------\n",
      "79        Trainable params\n",
      "0         Non-trainable params\n",
      "79        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataLog: Max number of particles = 4\n",
      "\n",
      "-------------------- Training information --------------------\n",
      "\n",
      "model: QuantumAngle2PCGNN QuantumAngle2PCGNN(\n",
      "  (gnn): MessagePassing()\n",
      "  (mlp): ClassicalMLP(\n",
      "    (net): Linear(in_features=6, out_features=1, bias=True)\n",
      "  )\n",
      ") \n",
      "config: {'time': '20230916_195512', 'wandb': False, 'project': 'g_eflow_QFCGNN', 'lr': 0.001, 'rnd_seed': 0, 'num_train_ratio': 0.8, 'num_bin_data': 1, 'batch_size': 64, 'num_workers': 0, 'max_epochs': 1, 'accelerator': 'cpu', 'fast_dev_run': False, 'log_every_n_steps': 32} \n",
      "train_info: {'rnd_seed': 0, 'model_name': 'QuantumAngle2PCGNN', 'preprocess_mode': 'normalize_pi', 'group_rnd': 'QuantumAngle2PCGNN_normalize_pi_gr1_gl2 | cut(800, 1000)_ptc4_bin10-1_R0.2', 'gnn_layers': 2, 'gnn_reupload': 1, 'gnn_qubits': 6, 'gnn_measurements': [(0, 'Z'), (1, 'Z'), (2, 'Z'), (3, 'Z'), (4, 'Z'), (5, 'Z')], 'sig': 'VzToZhToVevebb', 'bkg': 'VzToQCD', 'cut': (800, 1000), 'bin': 10, 'subjet_radius': 0.2, 'num_bin_data': 1, 'num_ptcs_limit': None, 'num_pt_ptcs': 4} \n",
      "wandb_info: {} \n",
      "--------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=32). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4fad3121cd4ed9a9fccca4c31397aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9518309d44f24ddda8d96d9827b600d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/yianchen/.pyenv/versions/3.9.12/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d67a6e0933d4e22be798f5f05951eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_roc_auc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.75            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_roc_auc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.75           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_info = {\"sig\": \"VzToZhToVevebb\", \"bkg\": \"VzToQCD\", \"cut\": (800, 1000), \"bin\":10, \"subjet_radius\":0.2, \"num_bin_data\":cf[\"num_bin_data\"], \"num_ptcs_limit\":None, \"num_pt_ptcs\":4}\n",
    "sig_fatjet_events = d_mg5_data.FatJetEvents(channel=data_info[\"sig\"], cut_pt=data_info[\"cut\"], subjet_radius=data_info[\"subjet_radius\"], num_pt_ptcs=data_info[\"num_pt_ptcs\"])\n",
    "bkg_fatjet_events = d_mg5_data.FatJetEvents(channel=data_info[\"bkg\"], cut_pt=data_info[\"cut\"], subjet_radius=data_info[\"subjet_radius\"], num_pt_ptcs=data_info[\"num_pt_ptcs\"])\n",
    "\n",
    "for rnd_seed in range(1):\n",
    "    cf[\"rnd_seed\"] = rnd_seed\n",
    "    L.seed_everything(cf[\"rnd_seed\"])\n",
    "\n",
    "    sig_events  = sig_fatjet_events.generate_uniform_pt_events(bin=data_info[\"bin\"], num_bin_data=data_info[\"num_bin_data\"], num_ptcs_limit=data_info[\"num_ptcs_limit\"])\n",
    "    bkg_events  = bkg_fatjet_events.generate_uniform_pt_events(bin=data_info[\"bin\"], num_bin_data=data_info[\"num_bin_data\"], num_ptcs_limit=data_info[\"num_ptcs_limit\"])\n",
    "    data_suffix = f\"cut{data_info['cut']}_ptc{data_info['num_pt_ptcs']}_bin{data_info['bin']}-{data_info['num_bin_data']}_R{data_info['subjet_radius']}\"\n",
    "\n",
    "    def train_classical(preprocess_mode, model_dict):\n",
    "        data_module = JetDataModule(sig_events, bkg_events, preprocess_mode)\n",
    "        model       = Classical2PCGNN(**model_dict)\n",
    "        go, gh, gl  = model_dict['gnn_out'], model_dict['gnn_hidden'], model_dict['gnn_layers']\n",
    "        mh, ml      = model_dict['mlp_hidden'], model_dict['mlp_layers']\n",
    "        train_info  = {\"rnd_seed\":cf[\"rnd_seed\"], \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode}\n",
    "        train_info[\"group_rnd\"] = f\"{model.__class__.__name__}_{preprocess_mode}_go{go}_gh{gh}_gl{gl}_mh{mh}_ml{ml} | {data_suffix}\"\n",
    "        train_info.update(model_dict)\n",
    "        train_info.update(data_info)\n",
    "        train(model, data_module, train_info)\n",
    "\n",
    "    def train_qtrivial(preprocess_mode, model_dict):\n",
    "        data_module = JetDataModule(sig_events, bkg_events, preprocess_mode)\n",
    "        model       = QuantumAngle2PCGNN(**model_dict)\n",
    "        gl, gr      = model_dict['gnn_layers'], model_dict['gnn_reupload']\n",
    "        train_info  = {\"rnd_seed\":cf[\"rnd_seed\"], \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode}\n",
    "        train_info[\"group_rnd\"] = f\"{model.__class__.__name__}_{preprocess_mode}_gr{gr}_gl{gl} | {data_suffix}\"\n",
    "        train_info.update(model_dict)\n",
    "        train_info.update(data_info)\n",
    "        train(model, data_module, train_info)\n",
    "\n",
    "    def train_qfcgnn(preprocess_mode, model_class, model_dict):\n",
    "        data_module = JetDataModule(sig_events, bkg_events, preprocess_mode, graph=False)\n",
    "        model       = model_class(**model_dict)\n",
    "        qidx, qnn   = model_dict['gnn_idx_qubits'], model_dict['gnn_nn_qubits']\n",
    "        gl, gr      = model_dict['gnn_layers'], model_dict['gnn_reupload']\n",
    "        num_qnn     = model_dict['gnn_num_qnn']\n",
    "        train_info  = {\"rnd_seed\":cf[\"rnd_seed\"], \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode}\n",
    "        train_info[\"group_rnd\"]  = f\"{model.__class__.__name__}_{preprocess_mode}_QNN{num_qnn}_qidx{qidx}_qnn{qnn}_gl{gl}_gr{gr} | {data_suffix}\"\n",
    "        train_info.update(model_dict)\n",
    "        train_info.update(data_info)\n",
    "        train(model, data_module, train_info, graph=False)\n",
    "\n",
    "    # # classical ML only\n",
    "    # for p_mode, go, gh, gl in product([\"\", \"normalize\", \"normalize_pi\", \"tri_eflow\"], [6], [6], [0,1,2]):\n",
    "    #     if p_mode in [\"\", \"normalize\", \"normalize_pi\"]:\n",
    "    #         gnn_in = 6\n",
    "    #     elif p_mode in [\"tri_eflow\"]:\n",
    "    #         gnn_in = 12\n",
    "    #     model_dict = {\"gnn_in\":gnn_in, \"gnn_out\":go, \"gnn_hidden\":gh, \"gnn_layers\":gl, \"mlp_hidden\":0, \"mlp_layers\":0}\n",
    "    #     train_classical(preprocess_mode=p_mode, model_dict=model_dict)\n",
    "\n",
    "    # Quantum Fully Connected Graph\n",
    "    for gnn_layers, gnn_reupload in product((1,2), (0,1)):\n",
    "        # Trivial GNN\n",
    "        preprocess_mode  = \"normalize_pi\"\n",
    "        # gnn_layers       = parse_args.q_gnn_layers\n",
    "        # gnn_reupload     = parse_args.q_gnn_reupload\n",
    "        gnn_qubits       = 6\n",
    "        gnn_num_qnn      = parse_args.q_gnn_num_qnn\n",
    "        model_dict       = {\"gnn_layers\":gnn_layers, \"gnn_reupload\":gnn_reupload, \"gnn_qubits\":gnn_qubits}\n",
    "        gnn_measurements = list(product(range(gnn_qubits), [\"Z\"]))\n",
    "        model_dict[\"gnn_measurements\"] = gnn_measurements\n",
    "        train_qtrivial(preprocess_mode, model_dict)\n",
    "\n",
    "        # # QFCGNN\n",
    "        # model_class     = QuantumRyFCGNN\n",
    "        # gnn_idx_qubits  = int(np.ceil(np.log2(max(\n",
    "        #     max(ak.count(sig_events[\"fast_pt\"], axis=1)), \n",
    "        #     max(ak.count(bkg_events[\"fast_pt\"], axis=1))))))\n",
    "        # preprocess_mode = \"normalize_pi\"\n",
    "        # # gnn_layers      = parse_args.q_gnn_layers\n",
    "        # # gnn_reupload    = parse_args.q_gnn_reupload\n",
    "        # gnn_num_qnn     = parse_args.q_gnn_num_qnn\n",
    "        # model_dict      = {\"gnn_idx_qubits\":gnn_idx_qubits, \"gnn_nn_qubits\":3, \"gnn_layers\":gnn_layers, \"gnn_reupload\":gnn_reupload, \"gnn_num_qnn\":gnn_num_qnn}\n",
    "        # train_qfcgnn(preprocess_mode, model_class, model_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abdd0d95ca50f233d1202cce1ba28eab5ada50f7ec17823ef40ef9b79347f6f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
