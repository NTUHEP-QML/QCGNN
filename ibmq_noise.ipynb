{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pre-trained QCGNN model on IBMQ\n",
    "\n",
    "1. Must have an existing [IBMQ](https://quantum.ibm.com) account.\n",
    "2. Create a local `./config.toml` file for PennyLane to link to the IBMQ, see [PennyLane configuration file](https://docs.pennylane.ai/en/latest/introduction/configuration.html#format) for further detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import pennylane as qml\n",
    "import torch\n",
    "\n",
    "from source.data.datamodule import JetTorchDataModule\n",
    "from source.data.opendata import TopQuarkEvents\n",
    "from source.models.qcgnn import QuantumRotQCGNN\n",
    "from source.training.litmodel import TorchLightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'TopQCD'\n",
    "\n",
    "with open(f\"configs/config.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "with open(f\"configs/ibmq.yaml\", 'r') as file:\n",
    "    ibmq_config = yaml.safe_load(file)\n",
    "    save_dir = os.path.join('ibmq_result', 'noise')\n",
    "    os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QCGNN model.\n",
    "n_I = ibmq_config['Pretrain']['n_I']\n",
    "\n",
    "for n_Q, rnd_seed in product([3, 6], range(5)):\n",
    "\n",
    "    L.seed_everything(rnd_seed)\n",
    "\n",
    "    num_data = ibmq_config['Data']['num_data']\n",
    "    num_ptcs = ibmq_config['Data']['num_ptcs']\n",
    "    dataset_config = {}\n",
    "    dataset_config.update(config['Data'])\n",
    "    dataset_config.update(config[dataset])\n",
    "    dataset_config['min_num_ptcs'] = num_ptcs\n",
    "    dataset_config['max_num_ptcs'] = num_ptcs\n",
    "\n",
    "    # Get 'TopQCD' events.\n",
    "    events = []\n",
    "    for y, channel in enumerate(['Top', 'QCD']):\n",
    "        y_true = [y] * num_data\n",
    "        top_qcd_events = TopQuarkEvents(mode='test', is_signal_new=y, **dataset_config)\n",
    "        events.append(top_qcd_events.generate_events(num_data))\n",
    "        print(f\"{channel} has {len(top_qcd_events.events)} events -> selected = {num_data}\\n\")\n",
    "\n",
    "    # Turn into data-module.    \n",
    "    data_module = JetTorchDataModule(\n",
    "        events=events,\n",
    "        num_train=0,\n",
    "        num_valid=0,\n",
    "        num_test=num_data * config[dataset]['num_classes'],\n",
    "        batch_size=ibmq_config['Data']['batch_size'],\n",
    "        max_num_ptcs=num_ptcs,\n",
    "        pi_scale=True\n",
    "    )\n",
    "\n",
    "    for noise_prob in [0, 1E-6, 1E-5, 1E-4, 1E-3, 1E-2]:\n",
    "        model = QuantumRotQCGNN(\n",
    "            num_ir_qubits=n_I,\n",
    "            num_nr_qubits=n_Q,\n",
    "            num_layers=n_Q//3,\n",
    "            num_reupload=2,\n",
    "            vqc_ansatz=qml.StronglyEntanglingLayers,\n",
    "            score_dim=1,\n",
    "            qdevice='default.mixed',\n",
    "            noise_prob=noise_prob,\n",
    "        )\n",
    "\n",
    "        # Load pre-trained checkpoint.\n",
    "        last_ckpt = torch.load(f\"./training_logs/WandbLogger/QCGNN_Rev1/QuantumRotQCGNN-nI4_nQ{n_Q}_L{n_Q//3}_R2_D0.00-TopQCD_P16_N25000-CQ0715-{rnd_seed}/checkpoints/last.ckpt\") # Last checkpoint.\n",
    "        best_ckpt = list(last_ckpt['callbacks'].values())[0]['best_model_path'] # Get the best checkpoint path.\n",
    "        best_state_dict = torch.load(best_ckpt)['state_dict'] # Load the best state dict.\n",
    "        best_state_dict = {k.replace('model.', ''): v for k, v in best_state_dict.items()} # Remove the 'model.' prefix.\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "        # Turn into a lightning model.\n",
    "        model.eval()\n",
    "        lit_model = TorchLightningModule(model=model, optimizer=None, score_dim=1, print_log=False)\n",
    "\n",
    "        # Start testing.\n",
    "        logger = CSVLogger(save_dir=save_dir, name=f\"Noise_{noise_prob:.0e}-Q{n_Q}-{rnd_seed}\")\n",
    "        trainer = L.Trainer(accelerator='cpu', default_root_dir=save_dir, logger=logger)\n",
    "        trainer.test(model=lit_model, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
