{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on IBMQ real device\n",
    "\n",
    "**Important**\n",
    "- `pip install pennylane-qiskit` before launching.\n",
    "- Create `./config.toml` file, see [PennyLane Configuration File](https://docs.pennylane.ai/en/latest/introduction/configuration.html#format) for further detail.\n",
    "\n",
    "This script runs the pretrained QCGNN on IBMQ real device with the default `shots` is 1024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import g_main\n",
    "import module_gmail\n",
    "import module_training\n",
    "\n",
    "# Output directory.\n",
    "general_config = g_main.json_config.copy()\n",
    "ibmq_dir = os.path.join(general_config[\"predictions_dir\"], \"ibmq\")\n",
    "os.makedirs(ibmq_dir, exist_ok=True)\n",
    "\n",
    "# Check `config.toml` file\n",
    "if not os.path.isfile(\"config.toml\"):\n",
    "    raise FileNotFoundError(\n",
    "        \"`./config.toml` file (containing IBMQ account token) not found, \"\n",
    "        \"see https://docs.pennylane.ai/en/latest/introduction/configuration.html#format \"\n",
    "        \"for futher detail.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and Dataset\n",
    "\n",
    "The number of dataset should be modified, otherwise too many data will queue for a long time. We choose the number of `num_bin_data = 100` such that the total number of data is\n",
    "\n",
    "> `num_bin_data` $*$ `bin` $*$ `2 channels` $*$ $(1 - $`data_ratio`$)$\n",
    "> \n",
    "> => $100 * 10 * 2 * (1-0.8)=400$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = 1024\n",
    "rnd_seed_range = range(3)\n",
    "\n",
    "# Modify the configuration.\n",
    "max_num_ptcs = 4\n",
    "general_config[\"batch_size\"] = 50\n",
    "general_config[\"max_num_ptcs\"] = max_num_ptcs\n",
    "general_config[\"pad_num_ptcs\"] = max_num_ptcs\n",
    "general_config[\"num_ptcs_range\"] = (max_num_ptcs, max_num_ptcs)\n",
    "general_config[\"num_bin_data\"] = 100\n",
    "\n",
    "# Quantum configurations.\n",
    "num_ir_qubits = int(np.ceil(np.log2(max_num_ptcs)))\n",
    "num_nr_qubits = 7\n",
    "num_layers = 1\n",
    "num_reupload = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config_list = [\n",
    "    # 2-prong v.s. 1-prong.\n",
    "    g_main.generate_data_config(\n",
    "        sig=\"VzToZhToVevebb\",\n",
    "        bkg=\"VzToQCD\",\n",
    "        abbrev=\"BB-QCD\",\n",
    "        general_config=general_config,\n",
    "    ),\n",
    "    \n",
    "    # 3-prong v.s. 1-prong.\n",
    "    g_main.generate_data_config(\n",
    "        sig=\"VzToTt\",\n",
    "        bkg=\"VzToQCD\",\n",
    "        abbrev=\"TT-QCD\",\n",
    "        general_config=general_config,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x: torch.Tensor, data_config: dict, quantum_config: dict):\n",
    "    \"\"\"Predict with the pretrained model.\n",
    "\n",
    "    Args:\n",
    "        x : torch.Tensor\n",
    "            Data to be predicted.\n",
    "        data_config : dict\n",
    "            Information about the data.\n",
    "        quantum_config : dict\n",
    "            Configurations of the quantum device.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor -> Predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # The `qidx` is fixed since we trained the model with `num_ir_qubits = 4`.\n",
    "    model_suffix = f\"qidx4_qnn{num_nr_qubits}_gl{num_layers}_gr{num_reupload}\"\n",
    "\n",
    "    # Get checkpoints file.\n",
    "    data_suffix = f\"{data_config['abbrev']}_ptc16_thres0.05-nb500_R0\"\n",
    "    ckpt_key = f\"QCGNN_IX_{model_suffix}_SUM-{data_suffix}\"\n",
    "    ckpt_path = module_training.get_ckpt_path(ckpt_key, general_config[\"rnd_seed\"])\n",
    "    \n",
    "    # Create model and load checkpoints.\n",
    "    model = g_main.QuantumRotQCGNN(\n",
    "        num_ir_qubits=num_ir_qubits,\n",
    "        num_nr_qubits=num_nr_qubits,\n",
    "        num_layers=num_layers,\n",
    "        num_reupload=num_reupload,\n",
    "        quantum_config=quantum_config,\n",
    "        return_meas=True\n",
    "    )\n",
    "\n",
    "    # Load the pretrained model and set to evaluation mode.\n",
    "    module_training.load_state_dict(model, ckpt_path)\n",
    "    model.eval()\n",
    "    \n",
    "    return model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on IBMQ\n",
    "\n",
    "A gmail will be sent from `maplexsendxemail@gmail.com` when the script is finished. See `except` and `else` sections in `try` for detail message of the email.\n",
    "\n",
    "The email settings are saved in `./gmail.json` (which is default inavailable in `.gitignore`), the detail structure of the `./gmail.json` file is:\n",
    "\n",
    "- \"from\": \"maplexsendxemail@gmail.com\",\n",
    "- \"to\": \"example@email.address\",\n",
    "- \"passwd\": \"xxxxxxxxxxxxxxxx\" (16-character password without spaces.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Choose an IBMQ backend\n",
    "    ibmq_backend = input(\"Enter IBMQ backend = \") or \"ibmq_qasm_simulator\"\n",
    "\n",
    "    # Prediction on IBMQ.\n",
    "    for data_config, rnd_seed in product(data_config_list, rnd_seed_range):\n",
    "        \n",
    "        # Seed everything.\n",
    "        general_config[\"rnd_seed\"] = rnd_seed\n",
    "        L.seed_everything(general_config[\"rnd_seed\"])\n",
    "        \n",
    "        # Create the data module.\n",
    "        data_module = g_main.generate_datamodule(\n",
    "            data_config=data_config,\n",
    "            data_ratio=general_config[\"data_ratio\"],\n",
    "            batch_size=general_config[\"batch_size\"],\n",
    "            graph=False\n",
    "        )\n",
    "\n",
    "        # Buffers for saving data.\n",
    "        x, y_true = torch.tensor([]), torch.tensor([])\n",
    "        y_penl, meas_penl = torch.tensor([]), torch.tensor([])\n",
    "        y_ibmq, meas_ibmq = torch.tensor([]), torch.tensor([])\n",
    "\n",
    "        # Batch data and batch label will start with prefix \"_\".\n",
    "        for _x, _y_true in tqdm(data_module.test_dataloader()):\n",
    "            \n",
    "            # Prediction on PennyLane.\n",
    "            _y_penl, _meas_penl = prediction(\n",
    "                x=_x,\n",
    "                data_config=data_config,\n",
    "                quantum_config={\n",
    "                    \"qdevice\": \"default.qubit\",\n",
    "                    \"diff_method\": \"best\",\n",
    "                    \"qbackend\": \"\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Prediction on IBMQ.\n",
    "            _y_ibmq, _meas_ibmq = prediction(\n",
    "                x=_x,\n",
    "                data_config=data_config,\n",
    "                quantum_config={\n",
    "                    \"qdevice\": \"qiskit.ibmq\",\n",
    "                    \"diff_method\": \"parameter-shift\",\n",
    "                    \"qbackend\": ibmq_backend,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Dataset and true labels.\n",
    "            x = torch.cat((x, _x))\n",
    "            y_true = torch.cat((y_true, _y_true))\n",
    "            \n",
    "            # Save predictions to buffers.\n",
    "            y_penl = torch.cat((y_penl, _y_penl))\n",
    "            y_ibmq = torch.cat((y_ibmq, _y_ibmq))\n",
    "            meas_penl = torch.cat((meas_penl, _meas_penl))\n",
    "            meas_ibmq = torch.cat((meas_ibmq, _meas_ibmq))\n",
    "\n",
    "        # Output dictionary    \n",
    "        result = {\n",
    "            \"x\": x, \"y_true\": y_true,\n",
    "            \"y_penl\": y_penl, \"meas_penl\": meas_penl,\n",
    "            \"y_ibmq\": y_ibmq, \"meas_ibmq\": meas_ibmq\n",
    "        }\n",
    "\n",
    "        # Save result to npy files.\n",
    "        npy_file = (\n",
    "            f\"{ibmq_backend}-s{shots}-{data_config['abbrev']}_\"\n",
    "            f\"r{general_config['rnd_seed']}-\"\n",
    "            f\"p{general_config['max_num_ptcs']}_\"\n",
    "            f\"n{general_config['num_bin_data']}_\"\n",
    "            f\"b{general_config['batch_size']}-\"\n",
    "            f\"{num_nr_qubits}_{num_layers}_{num_reupload}.npy\"\n",
    "        )\n",
    "        npy_path = os.path.join(ibmq_dir, npy_file)\n",
    "        np.save(npy_path, result, allow_pickle=True)\n",
    "\n",
    "except Exception as e:\n",
    "    subject = f\"Failed to run ibmq on {ibmq_backend}\"\n",
    "    message = str(e)\n",
    "\n",
    "else:\n",
    "    model_suffix = f\"qidx4_qnn{num_nr_qubits}_gl{num_layers}_gr{num_reupload}\"\n",
    "    subject = f\"Finished running ibmq on {ibmq_backend}\"\n",
    "    message = f\"Finish {model_suffix} with rnd_seed_range = {rnd_seed_range}\"\n",
    "\n",
    "finally:\n",
    "    if os.path.isfile(\"gmail.json\"):\n",
    "        module_gmail.send_email(subject, message, config=general_config)\n",
    "    else:\n",
    "        print(subject)\n",
    "        print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
