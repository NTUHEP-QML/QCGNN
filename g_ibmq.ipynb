{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "\n",
    "import g_main\n",
    "import module_model\n",
    "\n",
    "config = g_main.json_config[\"config\"]\n",
    "config[\"batch_size\"]   = 300\n",
    "config[\"rnd_seed\"]     = 0\n",
    "config[\"num_bin_data\"] = 25 # 25 * 10 * 2 * (1-0.8) = 100 test data\n",
    "L.seed_everything(config[\"rnd_seed\"])\n",
    "\n",
    "ibmq_dir = \"./ibmq\"\n",
    "os.makedirs(ibmq_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBMQQCGNN(module_model.QCGNN):\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = torch.unflatten(x, dim=-1, sizes=(2**self.num_ir_qubits, self.num_nr_qubits))\n",
    "        x = x.mT\n",
    "        meas = x.detach()\n",
    "        x = torch.sum(x, dim=-1) * (2**self.num_ir_qubits)\n",
    "        return x, meas\n",
    "\n",
    "class QuantumRotQCGNN(nn.Module):\n",
    "    def __init__(self, num_ir_qubits, num_nr_qubits, num_layers, num_reupload, quantum_config):\n",
    "        super().__init__()\n",
    "        if \"qiskit\" in quantum_config[\"qdevice\"]:\n",
    "            ctrl_enc = lambda _input, control_values: g_main.qiskit_encoding(_input, control_values, num_ir_qubits, num_nr_qubits)\n",
    "        else:\n",
    "            ctrl_enc = lambda _input, control_values: g_main.pennylane_encoding(_input, control_values, num_ir_qubits, num_nr_qubits)\n",
    "        self.phi = IBMQQCGNN(num_ir_qubits, num_nr_qubits, num_layers, num_reupload, ctrl_enc=ctrl_enc, **quantum_config)\n",
    "        self.mlp = module_model.ClassicalMLP(in_channel=num_nr_qubits, out_channel=1, hidden_channel=0, num_layers=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # inputs should be 1-dim for each data, otherwise it would be confused with batch shape\n",
    "        x = torch.flatten(x, start_dim=-2, end_dim=-1)\n",
    "        x, meas = self.phi(x)\n",
    "        x = self.mlp(x)\n",
    "        return x, meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn, gl, gr  = 3, 1, 3\n",
    "data_configs = [\n",
    "    {\"sig\": \"VzToZhToVevebb\", \"bkg\": \"VzToQCD\", \"abbrev\":\"BB-QCD\", \"cut\": (800, 1000), \"bin\":10, \"subjet_radius\":0, \"num_bin_data\":config[\"num_bin_data\"], \"num_pt_ptcs\":8},\n",
    "    {\"sig\": \"VzToTt\", \"bkg\": \"VzToQCD\", \"abbrev\":\"TT-QCD\", \"cut\": (800, 1000), \"bin\":10, \"subjet_radius\":0, \"num_bin_data\":config[\"num_bin_data\"], \"num_pt_ptcs\":8},\n",
    "]\n",
    "\n",
    "def load_state_dict(model, ckpt_path):\n",
    "    old_state_dict = torch.load(ckpt_path)[\"state_dict\"]\n",
    "    new_state_dict = {}\n",
    "    for old_key in old_state_dict.keys():\n",
    "        new_key = old_key[6:]\n",
    "        print(f\"ModelLog: {old_key} ---> {new_key}\")\n",
    "        new_state_dict[new_key] = old_state_dict[old_key]\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "def prediction(x, quantum_config):\n",
    "    # load model\n",
    "    model_name   = QuantumRotQCGNN.__name__\n",
    "    model_suffix = f\"qidx3_qnn{qnn}_gl{gl}_gr{gr}\"\n",
    "    ckpt_key  = f\"{model_name}_{model_suffix} | {data_config['abbrev']}_cut{data_config['cut']}\"\n",
    "    ckpt_path = g_main.get_ckpt(ckpt_key)\n",
    "    model     = QuantumRotQCGNN(3, qnn, gl, gr, quantum_config)\n",
    "    load_state_dict(model, ckpt_path)\n",
    "    model.eval()\n",
    "    return model(x)\n",
    "\n",
    "result = {}\n",
    "ibmq_backend = input(\"Enter IBMQ backend = \")\n",
    "for data_config in data_configs:\n",
    "    data_module = g_main.generate_datamodule(data_config, graph=False)\n",
    "    assert len(data_module.test_dataloader()) == 1, \"Check batch size, require 1 batch only\"\n",
    "    for x, y_true in data_module.test_dataloader():\n",
    "        y_penl_pred, meas_penl = prediction(x, {\"qdevice\": \"default.qubit\", \"diff_method\": \"best\", \"qbackend\": \"\"})\n",
    "        y_ibmq_pred, meas_ibmq = prediction(x, {\"qdevice\": \"qiskit.ibmq\", \"diff_method\": \"parameter-shift\", \"qbackend\": ibmq_backend})\n",
    "        y_qasm_pred, qasm_ibmq = prediction(x, {\"qdevice\": \"qiskit.ibmq\", \"diff_method\": \"parameter-shift\", \"qbackend\": \"ibmq_qasm_simulator\"})\n",
    "    channel_result = {\"x\":x, \"y_true\":y_true, \"y_penl_pred\":y_penl_pred, \"meas_penl\":meas_penl, \"y_qasm_pred\":y_qasm_pred, \"qasm_ibmq\":qasm_ibmq, \"y_ibmq_pred\":y_ibmq_pred, \"meas_ibmq\":meas_ibmq}\n",
    "    result[data_config[\"abbrev\"]] = channel_result\n",
    "\n",
    "npy_file = os.path.join(ibmq_dir, f\"ibmq_{ibmq_backend}_{config['rnd_seed']}-{config['num_bin_data']}_{config['batch_size']}-{qnn}_{gl}_{gr}.npy\")\n",
    "np.save(npy_file, result, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
