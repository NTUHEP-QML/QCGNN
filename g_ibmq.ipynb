{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------------------------------------------------------------\n",
      "#                         FastJet release 3.4.0\n",
      "#                 M. Cacciari, G.P. Salam and G. Soyez                  \n",
      "#     A software package for jet finding and analysis at colliders      \n",
      "#                           http://fastjet.fr                           \n",
      "#\t                                                                      \n",
      "# Please cite EPJC72(2012)1896 [arXiv:1111.6097] if you use this package\n",
      "# for scientific work and optionally PLB641(2006)57 [hep-ph/0512210].   \n",
      "#                                                                       \n",
      "# FastJet is provided without warranty under the GNU GPL v2 or higher.  \n",
      "# It uses T. Chan's closest pair algorithm, S. Fortune's Voronoi code,\n",
      "# CGAL and 3rd party plugin jet algorithms. See COPYING file for details.\n",
      "#--------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "\n",
    "import g_main\n",
    "import module_model\n",
    "\n",
    "shots = 100000\n",
    "\n",
    "config = g_main.json_config[\"config\"]\n",
    "config[\"batch_size\"]   = 300\n",
    "config[\"rnd_seed\"]     = 0\n",
    "config[\"num_pt_ptcs\"]  = 4\n",
    "config[\"num_bin_data\"] = 25 # 25 * 10 * 2 * (1-0.8) = 100 test data\n",
    "L.seed_everything(config[\"rnd_seed\"])\n",
    "\n",
    "ibmq_dir = \"./ibmq\"\n",
    "os.makedirs(ibmq_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBMQQCGNN(module_model.QCGNN):\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = torch.unflatten(x, dim=-1, sizes=(2**self.num_ir_qubits, self.num_nr_qubits))\n",
    "        x = x.mT\n",
    "        meas = x.detach()\n",
    "        x = torch.sum(x, dim=-1) * self.scale\n",
    "        return x, meas\n",
    "\n",
    "class QuantumRotQCGNN(nn.Module):\n",
    "    def __init__(self, num_ir_qubits, num_nr_qubits, num_layers, num_reupload, quantum_config):\n",
    "        super().__init__()\n",
    "        if \"qiskit\" in quantum_config[\"qdevice\"]:\n",
    "            ctrl_enc = lambda _input, control_values: g_main.qiskit_encoding(_input, control_values, num_ir_qubits, num_nr_qubits)\n",
    "        else:\n",
    "            ctrl_enc = lambda _input, control_values: g_main.pennylane_encoding(_input, control_values, num_ir_qubits, num_nr_qubits)\n",
    "        self.phi = IBMQQCGNN(num_ir_qubits, num_nr_qubits, num_layers, num_reupload, ctrl_enc=ctrl_enc, shots=shots, **quantum_config)\n",
    "        self.mlp = module_model.ClassicalMLP(in_channel=num_nr_qubits, out_channel=1, hidden_channel=0, num_layers=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # inputs should be 1-dim for each data, otherwise it would be confused with batch shape\n",
    "        x = torch.flatten(x, start_dim=-2, end_dim=-1)\n",
    "        x, meas = self.phi(x)\n",
    "        x = self.mlp(x)\n",
    "        return x.detach(), meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DataLog: Now loading hdf5 file VzToZhToVevebb|c800_1000_r0.hdf5\n",
      "# DataLog: Successfully loading hdf5 file VzToZhToVevebb|c800_1000_r0.hdf5\n",
      "\n",
      "# DataLog: Now loading hdf5 file VzToQCD|c800_1000_r0.hdf5\n",
      "# DataLog: Successfully loading hdf5 file VzToQCD|c800_1000_r0.hdf5\n",
      "\n",
      "\n",
      "# DataLog: Max number of particles = 4\n",
      "\n",
      "# ModelLog: ckpt found at ./ckpt/QuantumRotQCGNN_qidx3_qnn3_gl1_gr3 | BB-QCD_cut(800, 1000)_ptc8_bin10-500_R0 | 20231105_slurm_0/checkpoints/epoch=29-step=2400.ckpt\n",
      "# ModelLog: Quantum device  = default.qubit | Qubits (IR, WK, NR) = (2, 0, 3)\n",
      "ModelLog: model.phi.net.0.weights ---> phi.net.0.weights\n",
      "ModelLog: model.mlp.net.weight ---> mlp.net.weight\n",
      "ModelLog: model.mlp.net.bias ---> mlp.net.bias\n",
      "# ModelLog: ckpt found at ./ckpt/QuantumRotQCGNN_qidx3_qnn3_gl1_gr3 | BB-QCD_cut(800, 1000)_ptc8_bin10-500_R0 | 20231105_slurm_0/checkpoints/epoch=29-step=2400.ckpt\n",
      "# ModelLog: Quantum device  = qiskit.ibmq | Qubits (IR, WK, NR) = (2, 1, 3)\n",
      "ModelLog: model.phi.net.0.weights ---> phi.net.0.weights\n",
      "ModelLog: model.mlp.net.weight ---> mlp.net.weight\n",
      "ModelLog: model.mlp.net.bias ---> mlp.net.bias\n"
     ]
    }
   ],
   "source": [
    "qidx = int(np.ceil(np.log2(config[\"num_pt_ptcs\"])))\n",
    "qnn, gl, gr  = 9, 1, 9\n",
    "data_configs = [\n",
    "    {\"sig\": \"VzToZhToVevebb\", \"bkg\": \"VzToQCD\", \"abbrev\":\"BB-QCD\", \"cut\": (800, 1000), \"bin\":10, \"subjet_radius\":0, \"num_bin_data\":config[\"num_bin_data\"], \"num_pt_ptcs\":config[\"num_pt_ptcs\"]},\n",
    "    {\"sig\": \"VzToTt\", \"bkg\": \"VzToQCD\", \"abbrev\":\"TT-QCD\", \"cut\": (800, 1000), \"bin\":10, \"subjet_radius\":0, \"num_bin_data\":config[\"num_bin_data\"], \"num_pt_ptcs\":config[\"num_pt_ptcs\"]},\n",
    "]\n",
    "\n",
    "def load_state_dict(model, ckpt_path):\n",
    "    old_state_dict = torch.load(ckpt_path)[\"state_dict\"]\n",
    "    new_state_dict = {}\n",
    "    for old_key in old_state_dict.keys():\n",
    "        new_key = old_key[6:]\n",
    "        print(f\"ModelLog: {old_key} ---> {new_key}\")\n",
    "        new_state_dict[new_key] = old_state_dict[old_key]\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "def prediction(x, quantum_config):\n",
    "    # load model\n",
    "    model_name   = QuantumRotQCGNN.__name__\n",
    "    model_suffix = f\"qidx3_qnn{qnn}_gl{gl}_gr{gr}\"\n",
    "    ckpt_key  = f\"{model_name}_{model_suffix} | {data_config['abbrev']}_cut{data_config['cut']}\"\n",
    "    ckpt_path = g_main.get_ckpt(ckpt_key)\n",
    "    model     = QuantumRotQCGNN(qidx, qnn, gl, gr, quantum_config)\n",
    "    load_state_dict(model, ckpt_path)\n",
    "    model.eval()\n",
    "    return model(x)\n",
    "\n",
    "result = {}\n",
    "ibmq_backend = input(\"Enter IBMQ backend = \")\n",
    "for data_config in data_configs:\n",
    "    data_module = g_main.generate_datamodule(data_config, graph=False)\n",
    "    assert len(data_module.test_dataloader()) == 1, \"Check batch size, require 1 batch only\"\n",
    "    for x, y_true in data_module.test_dataloader():\n",
    "        y_penl, meas_penl = prediction(x, {\"qdevice\": \"default.qubit\", \"diff_method\": \"best\", \"qbackend\": \"\"})\n",
    "        y_ibmq, meas_ibmq = prediction(x, {\"qdevice\": \"qiskit.ibmq\", \"diff_method\": \"parameter-shift\", \"qbackend\": ibmq_backend})\n",
    "        y_qasm, meas_qasm = prediction(x, {\"qdevice\": \"qiskit.ibmq\", \"diff_method\": \"parameter-shift\", \"qbackend\": \"ibmq_qasm_simulator\"})\n",
    "    channel_result = {\"x\":x, \"y_true\":y_true, \"y_penl\":y_penl, \"meas_penl\":meas_penl, \"y_qasm\":y_qasm, \"meas_qasm\":meas_qasm, \"y_ibmq\":y_ibmq, \"meas_ibmq\":meas_ibmq}\n",
    "    result[data_config[\"abbrev\"]] = channel_result\n",
    "\n",
    "npy_file = os.path.join(ibmq_dir, f\"{ibmq_backend}_r{config['rnd_seed']}-p_{config['num_pt_ptcs']}_n{config['num_bin_data']}_b{config['batch_size']}-{qnn}_{gl}_{gr}.npy\")\n",
    "np.save(npy_file, result, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
